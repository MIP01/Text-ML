{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kategori</th>\n",
       "      <th>komentar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non-bullying</td>\n",
       "      <td>['kakak', 'tidur', 'sudah', 'pagi', 'tidak bol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-bullying</td>\n",
       "      <td>['makan', 'nasi', 'padang', 'saja', 'badan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bullying</td>\n",
       "      <td>['suka', 'cukur', 'jembut', 'manggung']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-bullying</td>\n",
       "      <td>['hai', 'kakak', 'isyana', 'ngefans', 'sekali'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-bullying</td>\n",
       "      <td>['manusia', 'bidadari', 'sih', 'heran', 'deh',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       kategori                                           komentar\n",
       "0  Non-bullying  ['kakak', 'tidur', 'sudah', 'pagi', 'tidak bol...\n",
       "1  Non-bullying       ['makan', 'nasi', 'padang', 'saja', 'badan']\n",
       "2      Bullying            ['suka', 'cukur', 'jembut', 'manggung']\n",
       "3  Non-bullying  ['hai', 'kakak', 'isyana', 'ngefans', 'sekali'...\n",
       "4  Non-bullying  ['manusia', 'bidadari', 'sih', 'heran', 'deh',..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset yang telah dipreprocessing\n",
    "df = pd.read_csv(\"Text_Preprocessing.csv\", usecols=[\"Kategori\", \"Komentar_tokens_stemmed\"])\n",
    "df.columns = [\"kategori\", \"komentar\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn TF-IDF Formula\n",
    "Formula untuk menghitung IDF pada Scikit-Learn berbeda, \n",
    "\n",
    "* jika parameter smooth_idf=True pada TfidfVectorizer\n",
    ">idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1\n",
    "\n",
    "* sebaliknya jika smooth_idf=False\n",
    ">idf(t) = log [ n / df(t) ] + 1\n",
    "\n",
    "pada featuring ini menggunakan smooth_idf=True, supaya kata-kata yang jarang muncul tetap memiliki nilai pada pembobotan "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menggunakan L2 Normalization\n",
    "* L1 normalization memberikan bobot yang sama pada setiap nilai  \n",
    "* L2 normalization memberikan bobot yang lebih besar pada nilai yang lebih besar dan bobot yang lebih kecil pada nilai yang lebih kecil\n",
    "\n",
    "Sparse matrix dengan size (n_samples, n_feature) pada Scikit-Learn akan di normalisasi ke normalizer L2 by default, dengan formula,\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Kita dapat memilih untuk tidak menggunakan normalizer pada TfidfVectorizer dengan menambahkan parameter norm=None ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menghitung TF-IDF bigram dan trigram\n",
    "Untuk menghitung TF-IDF bigram dan trigram menggunakan Scikit-Learn, kita dapat menambahkan argument ngram_range=(min_n, max_n). \n",
    "\n",
    "min_n dan max_n merupakan batasan minimum dan maksimum ngram yang akan digunakan pada fungsi TfidfVectorizer() maupun CountVectorizer() .\n",
    "\n",
    "* ngram_range=(1,1) artinya hanya hitung TFIDF unigram,\n",
    "\n",
    "* ngram_range=(1,2) artinya hitung TFIDF unigram dan bigram,\n",
    "\n",
    "* ngram_range=(2,2) artinya hanya hitung TFIDF bigram,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- TF-IDF on data -------\n",
      "TF-IDF  <class 'scipy.sparse.csr.csr_matrix'> (650, 1319)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Feature Engineering \n",
    "print (\"------- TF-IDF on data -------\")\n",
    "\n",
    "# mendapatkan TF\n",
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "TF_vec = vect.fit_transform(df['komentar'])\n",
    "\n",
    "# normalisasi pada vektor TF\n",
    "# Hal ini dilakukan untuk memastikan bahwa vektor memiliki panjang Euclidean yang sama.\n",
    "norm_TF_vec = normalize(TF_vec, axis=1)\n",
    "\n",
    "# Menghitung TF-IDF\n",
    "tf_idf = TfidfVectorizer(binary=True, ngram_range=(1,1), smooth_idf=True)\n",
    "tfs = tf_idf.fit_transform(df['komentar'])\n",
    "IDF_vec = tf_idf.idf_\n",
    "\n",
    "tfidf_mat = tfs.multiply(IDF_vec).toarray()\n",
    "\n",
    "\n",
    "print(\"TF-IDF \", type(tfs), tfs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>aamiin</th>\n",
       "      <th>abai</th>\n",
       "      <th>abal</th>\n",
       "      <th>abu</th>\n",
       "      <th>activity</th>\n",
       "      <th>ada</th>\n",
       "      <th>adab</th>\n",
       "      <th>adam</th>\n",
       "      <th>adaptasi</th>\n",
       "      <th>adi</th>\n",
       "      <th>...</th>\n",
       "      <th>yemuke</th>\n",
       "      <th>yesus</th>\n",
       "      <th>you</th>\n",
       "      <th>younger</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youtuber</th>\n",
       "      <th>yuhu</th>\n",
       "      <th>yutuber</th>\n",
       "      <th>ziu</th>\n",
       "      <th>zo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows × 1319 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aamiin abai abal  abu activity  ada adab adam adaptasi  adi  ... yemuke  \\\n",
       "0      0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "1      0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "2      0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "3      0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "4      0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "..     ...  ...  ...  ...      ...  ...  ...  ...      ...  ...  ...    ...   \n",
       "645    0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "646    0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "647    0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "648    0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "649    0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "\n",
       "    yesus  you younger youtube youtuber yuhu yutuber  ziu   zo  \n",
       "0     0.0  0.0     0.0     0.0      0.0  0.0     0.0  0.0  0.0  \n",
       "1     0.0  0.0     0.0     0.0      0.0  0.0     0.0  0.0  0.0  \n",
       "2     0.0  0.0     0.0     0.0      0.0  0.0     0.0  0.0  0.0  \n",
       "3     0.0  0.0     0.0     0.0      0.0  0.0     0.0  0.0  0.0  \n",
       "4     0.0  0.0     0.0     0.0      0.0  0.0     0.0  0.0  0.0  \n",
       "..    ...  ...     ...     ...      ...  ...     ...  ...  ...  \n",
       "645   0.0  0.0     0.0     0.0      0.0  0.0     0.0  0.0  0.0  \n",
       "646   0.0  0.0     0.0     0.0      0.0  0.0     0.0  0.0  0.0  \n",
       "647   0.0  0.0     0.0     0.0      0.0  0.0     0.0  0.0  0.0  \n",
       "648   0.0  0.0     0.0     0.0      0.0  0.0     0.0  0.0  0.0  \n",
       "649   0.0  0.0     0.0     0.0      0.0  0.0     0.0  0.0  0.0  \n",
       "\n",
       "[650 rows x 1319 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualisasi tabel\n",
    "a = tf_idf.get_feature_names()\n",
    "tf_tb = norm_TF_vec.multiply(IDF_vec).toarray()\n",
    "dfbtf =pd.DataFrame(data=tfidf_mat,columns=[a])\n",
    "dfbtf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>anjing</td>\n",
       "      <td>69.297764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>kamu</td>\n",
       "      <td>67.922752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>cantik</td>\n",
       "      <td>60.850035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>saja</td>\n",
       "      <td>56.056245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>sudah</td>\n",
       "      <td>55.631325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>bocor</td>\n",
       "      <td>1.908859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>siain</td>\n",
       "      <td>1.908859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>for</td>\n",
       "      <td>1.891404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>jakarta</td>\n",
       "      <td>1.891404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>performance</td>\n",
       "      <td>1.891404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             term       rank\n",
       "47         anjing  69.297764\n",
       "551          kamu  67.922752\n",
       "224        cantik  60.850035\n",
       "1053         saja  56.056245\n",
       "1164        sudah  55.631325\n",
       "...           ...        ...\n",
       "176         bocor   1.908859\n",
       "1121        siain   1.908859\n",
       "355           for   1.891404\n",
       "499       jakarta   1.891404\n",
       "976   performance   1.891404\n",
       "\n",
       "[1319 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#menampilkan hasil term dengan TF-IDF terbesar\n",
    "terms = tf_idf.get_feature_names()\n",
    "\n",
    "# sum tfidf frequency of each term through documents\n",
    "sums = tfidf_mat.sum(axis=0)\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "data = []\n",
    "for col, term in enumerate(terms):\n",
    "    data.append((term, sums[col] ))\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','rank'])\n",
    "ranking.sort_values('rank', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Iterasi 1 - Accuracy: 0.9\n",
      "Iterasi 2 - Accuracy: 0.9076923076923077\n",
      "Iterasi 3 - Accuracy: 0.8692307692307693\n",
      "Iterasi 4 - Accuracy: 0.8615384615384616\n",
      "Iterasi 5 - Accuracy: 0.8307692307692308\n",
      "Iterasi 6 - Accuracy: 0.9076923076923077\n",
      "Iterasi 7 - Accuracy: 0.8307692307692308\n",
      "Iterasi 8 - Accuracy: 0.8692307692307693\n",
      "Iterasi 9 - Accuracy: 0.9076923076923077\n",
      "Iterasi 10 - Accuracy: 0.8615384615384616\n",
      "Iterasi 11 - Accuracy: 0.8923076923076924\n",
      "Iterasi 12 - Accuracy: 0.8307692307692308\n",
      "Iterasi 13 - Accuracy: 0.9\n",
      "Iterasi 14 - Accuracy: 0.9\n",
      "Iterasi 15 - Accuracy: 0.8615384615384616\n",
      "Iterasi 16 - Accuracy: 0.8692307692307693\n",
      "Iterasi 17 - Accuracy: 0.8692307692307693\n",
      "Iterasi 18 - Accuracy: 0.9\n",
      "Iterasi 19 - Accuracy: 0.8384615384615385\n",
      "Iterasi 20 - Accuracy: 0.8461538461538461\n",
      "Iterasi 21 - Accuracy: 0.8769230769230769\n",
      "Iterasi 22 - Accuracy: 0.8461538461538461\n",
      "Iterasi 23 - Accuracy: 0.8461538461538461\n",
      "Iterasi 24 - Accuracy: 0.8461538461538461\n",
      "Iterasi 25 - Accuracy: 0.9\n",
      "Iterasi 26 - Accuracy: 0.8384615384615385\n",
      "Iterasi 27 - Accuracy: 0.8461538461538461\n",
      "Iterasi 28 - Accuracy: 0.8923076923076924\n",
      "Iterasi 29 - Accuracy: 0.8538461538461538\n",
      "Iterasi 30 - Accuracy: 0.8615384615384616\n",
      "\n",
      "Model: Decision Tree\n",
      "Iterasi 1 - Accuracy: 0.7538461538461538\n",
      "Iterasi 2 - Accuracy: 0.8\n",
      "Iterasi 3 - Accuracy: 0.7307692307692307\n",
      "Iterasi 4 - Accuracy: 0.7846153846153846\n",
      "Iterasi 5 - Accuracy: 0.8153846153846154\n",
      "Iterasi 6 - Accuracy: 0.7846153846153846\n",
      "Iterasi 7 - Accuracy: 0.7307692307692307\n",
      "Iterasi 8 - Accuracy: 0.7615384615384615\n",
      "Iterasi 9 - Accuracy: 0.7692307692307693\n",
      "Iterasi 10 - Accuracy: 0.7846153846153846\n",
      "Iterasi 11 - Accuracy: 0.8\n",
      "Iterasi 12 - Accuracy: 0.7692307692307693\n",
      "Iterasi 13 - Accuracy: 0.7846153846153846\n",
      "Iterasi 14 - Accuracy: 0.7769230769230769\n",
      "Iterasi 15 - Accuracy: 0.7692307692307693\n",
      "Iterasi 16 - Accuracy: 0.7769230769230769\n",
      "Iterasi 17 - Accuracy: 0.7384615384615385\n",
      "Iterasi 18 - Accuracy: 0.7384615384615385\n",
      "Iterasi 19 - Accuracy: 0.7461538461538462\n",
      "Iterasi 20 - Accuracy: 0.6923076923076923\n",
      "Iterasi 21 - Accuracy: 0.7769230769230769\n",
      "Iterasi 22 - Accuracy: 0.7692307692307693\n",
      "Iterasi 23 - Accuracy: 0.7538461538461538\n",
      "Iterasi 24 - Accuracy: 0.7307692307692307\n",
      "Iterasi 25 - Accuracy: 0.8076923076923077\n",
      "Iterasi 26 - Accuracy: 0.7307692307692307\n",
      "Iterasi 27 - Accuracy: 0.7615384615384615\n",
      "Iterasi 28 - Accuracy: 0.7769230769230769\n",
      "Iterasi 29 - Accuracy: 0.7538461538461538\n",
      "Iterasi 30 - Accuracy: 0.7538461538461538\n",
      "\n",
      "Model: Random Forest\n",
      "Iterasi 1 - Accuracy: 0.8769230769230769\n",
      "Iterasi 2 - Accuracy: 0.823076923076923\n",
      "Iterasi 3 - Accuracy: 0.8846153846153846\n",
      "Iterasi 4 - Accuracy: 0.823076923076923\n",
      "Iterasi 5 - Accuracy: 0.7846153846153846\n",
      "Iterasi 6 - Accuracy: 0.8\n",
      "Iterasi 7 - Accuracy: 0.8307692307692308\n",
      "Iterasi 8 - Accuracy: 0.8153846153846154\n",
      "Iterasi 9 - Accuracy: 0.7923076923076923\n",
      "Iterasi 10 - Accuracy: 0.8153846153846154\n",
      "Iterasi 11 - Accuracy: 0.8153846153846154\n",
      "Iterasi 12 - Accuracy: 0.8538461538461538\n",
      "Iterasi 13 - Accuracy: 0.8307692307692308\n",
      "Iterasi 14 - Accuracy: 0.823076923076923\n",
      "Iterasi 15 - Accuracy: 0.823076923076923\n",
      "Iterasi 16 - Accuracy: 0.7538461538461538\n",
      "Iterasi 17 - Accuracy: 0.7615384615384615\n",
      "Iterasi 18 - Accuracy: 0.7692307692307693\n",
      "Iterasi 19 - Accuracy: 0.8923076923076924\n",
      "Iterasi 20 - Accuracy: 0.8461538461538461\n",
      "Iterasi 21 - Accuracy: 0.8846153846153846\n",
      "Iterasi 22 - Accuracy: 0.7923076923076923\n",
      "Iterasi 23 - Accuracy: 0.8384615384615385\n",
      "Iterasi 24 - Accuracy: 0.7615384615384615\n",
      "Iterasi 25 - Accuracy: 0.8\n",
      "Iterasi 26 - Accuracy: 0.8461538461538461\n",
      "Iterasi 27 - Accuracy: 0.8153846153846154\n",
      "Iterasi 28 - Accuracy: 0.8307692307692308\n",
      "Iterasi 29 - Accuracy: 0.8384615384615385\n",
      "Iterasi 30 - Accuracy: 0.9\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Iterasi 1 - Accuracy: 0.49230769230769234\n",
      "Iterasi 2 - Accuracy: 0.5307692307692308\n",
      "Iterasi 3 - Accuracy: 0.6461538461538462\n",
      "Iterasi 4 - Accuracy: 0.5615384615384615\n",
      "Iterasi 5 - Accuracy: 0.6230769230769231\n",
      "Iterasi 6 - Accuracy: 0.5692307692307692\n",
      "Iterasi 7 - Accuracy: 0.6384615384615384\n",
      "Iterasi 8 - Accuracy: 0.5846153846153846\n",
      "Iterasi 9 - Accuracy: 0.5923076923076923\n",
      "Iterasi 10 - Accuracy: 0.676923076923077\n",
      "Iterasi 11 - Accuracy: 0.5769230769230769\n",
      "Iterasi 12 - Accuracy: 0.5769230769230769\n",
      "Iterasi 13 - Accuracy: 0.6538461538461539\n",
      "Iterasi 14 - Accuracy: 0.6846153846153846\n",
      "Iterasi 15 - Accuracy: 0.6538461538461539\n",
      "Iterasi 16 - Accuracy: 0.6230769230769231\n",
      "Iterasi 17 - Accuracy: 0.6692307692307692\n",
      "Iterasi 18 - Accuracy: 0.6538461538461539\n",
      "Iterasi 19 - Accuracy: 0.5923076923076923\n",
      "Iterasi 20 - Accuracy: 0.5769230769230769\n",
      "Iterasi 21 - Accuracy: 0.6692307692307692\n",
      "Iterasi 22 - Accuracy: 0.5461538461538461\n",
      "Iterasi 23 - Accuracy: 0.5769230769230769\n",
      "Iterasi 24 - Accuracy: 0.6384615384615384\n",
      "Iterasi 25 - Accuracy: 0.5769230769230769\n",
      "Iterasi 26 - Accuracy: 0.5923076923076923\n",
      "Iterasi 27 - Accuracy: 0.6384615384615384\n",
      "Iterasi 28 - Accuracy: 0.5769230769230769\n",
      "Iterasi 29 - Accuracy: 0.6\n",
      "Iterasi 30 - Accuracy: 0.5692307692307692\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Iterasi 1 - Accuracy: 0.8\n",
      "Iterasi 2 - Accuracy: 0.7769230769230769\n",
      "Iterasi 3 - Accuracy: 0.7615384615384615\n",
      "Iterasi 4 - Accuracy: 0.7923076923076923\n",
      "Iterasi 5 - Accuracy: 0.7923076923076923\n",
      "Iterasi 6 - Accuracy: 0.7461538461538462\n",
      "Iterasi 7 - Accuracy: 0.7846153846153846\n",
      "Iterasi 8 - Accuracy: 0.7692307692307693\n",
      "Iterasi 9 - Accuracy: 0.7923076923076923\n",
      "Iterasi 10 - Accuracy: 0.7692307692307693\n",
      "Iterasi 11 - Accuracy: 0.8153846153846154\n",
      "Iterasi 12 - Accuracy: 0.8153846153846154\n",
      "Iterasi 13 - Accuracy: 0.7923076923076923\n",
      "Iterasi 14 - Accuracy: 0.7846153846153846\n",
      "Iterasi 15 - Accuracy: 0.7692307692307693\n",
      "Iterasi 16 - Accuracy: 0.8076923076923077\n",
      "Iterasi 17 - Accuracy: 0.7846153846153846\n",
      "Iterasi 18 - Accuracy: 0.7615384615384615\n",
      "Iterasi 19 - Accuracy: 0.8076923076923077\n",
      "Iterasi 20 - Accuracy: 0.7769230769230769\n",
      "Iterasi 21 - Accuracy: 0.8307692307692308\n",
      "Iterasi 22 - Accuracy: 0.8153846153846154\n",
      "Iterasi 23 - Accuracy: 0.8384615384615385\n",
      "Iterasi 24 - Accuracy: 0.7692307692307693\n",
      "Iterasi 25 - Accuracy: 0.8076923076923077\n",
      "Iterasi 26 - Accuracy: 0.7769230769230769\n",
      "Iterasi 27 - Accuracy: 0.8307692307692308\n",
      "Iterasi 28 - Accuracy: 0.7461538461538462\n",
      "Iterasi 29 - Accuracy: 0.8\n",
      "Iterasi 30 - Accuracy: 0.7846153846153846\n",
      "\n",
      "Model: Multinomial Naive Bayes\n",
      "Iterasi 1 - Accuracy: 0.8615384615384616\n",
      "Iterasi 2 - Accuracy: 0.823076923076923\n",
      "Iterasi 3 - Accuracy: 0.8461538461538461\n",
      "Iterasi 4 - Accuracy: 0.8153846153846154\n",
      "Iterasi 5 - Accuracy: 0.8153846153846154\n",
      "Iterasi 6 - Accuracy: 0.8384615384615385\n",
      "Iterasi 7 - Accuracy: 0.8615384615384616\n",
      "Iterasi 8 - Accuracy: 0.8538461538461538\n",
      "Iterasi 9 - Accuracy: 0.8384615384615385\n",
      "Iterasi 10 - Accuracy: 0.8461538461538461\n",
      "Iterasi 11 - Accuracy: 0.8615384615384616\n",
      "Iterasi 12 - Accuracy: 0.8846153846153846\n",
      "Iterasi 13 - Accuracy: 0.8461538461538461\n",
      "Iterasi 14 - Accuracy: 0.8846153846153846\n",
      "Iterasi 15 - Accuracy: 0.8\n",
      "Iterasi 16 - Accuracy: 0.8615384615384616\n",
      "Iterasi 17 - Accuracy: 0.8\n",
      "Iterasi 18 - Accuracy: 0.8538461538461538\n",
      "Iterasi 19 - Accuracy: 0.8\n",
      "Iterasi 20 - Accuracy: 0.8461538461538461\n",
      "Iterasi 21 - Accuracy: 0.8384615384615385\n",
      "Iterasi 22 - Accuracy: 0.8384615384615385\n",
      "Iterasi 23 - Accuracy: 0.8846153846153846\n",
      "Iterasi 24 - Accuracy: 0.8461538461538461\n",
      "Iterasi 25 - Accuracy: 0.8153846153846154\n",
      "Iterasi 26 - Accuracy: 0.8384615384615385\n",
      "Iterasi 27 - Accuracy: 0.7923076923076923\n",
      "Iterasi 28 - Accuracy: 0.8153846153846154\n",
      "Iterasi 29 - Accuracy: 0.8153846153846154\n",
      "Iterasi 30 - Accuracy: 0.8384615384615385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# tentukan jumlah pengulangan\n",
    "n_repeats = 30\n",
    "\n",
    "# List untuk menyimpan rata-rata akurasi\n",
    "average_accuracies = []\n",
    "\n",
    "# membagi data ke training and testing sets\n",
    "X = tfidf_mat #hasil featuring\n",
    "y = df['kategori']#label pada dataset\n",
    "\n",
    "# Membuat objek untuk setiap model\n",
    "models = {'Logistic Regression': LogisticRegression(),\n",
    "          'Decision Tree': DecisionTreeClassifier(),\n",
    "          'Random Forest': RandomForestClassifier(),\n",
    "          'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=3, algorithm='brute'),\n",
    "          'Gradient Boosting': GradientBoostingClassifier(),\n",
    "          'Multinomial Naive Bayes': MultinomialNB()}\n",
    "\n",
    "# Melakukan 30 iterasi untuk setiap model dengan test set yang berbeda\n",
    "for model_name, model in models.items():\n",
    "    accuracy_list = []  # Untuk menyimpan akurasi pada setiap iterasi\n",
    "    print(f\"Model: {model_name}\")\n",
    "    \n",
    "    for i in range(n_repeats):\n",
    "        # test_size 0.2 artinya 20% dari total data akan dijadikan test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        \n",
    "        # Melatih model menggunakan data training\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Melakukan prediksi pada data testing\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Save the train-test split data using pickle\n",
    "        with open('true_labels.pkl', 'wb') as f:\n",
    "            pickle.dump((X_train, X_test, y_train, y_test), f)\n",
    "        \n",
    "        # Menghitung akurasi pada setiap iterasi\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Iterasi {i+1} - Accuracy: {accuracy}\")\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    accuracy_mean = np.mean(accuracy_list)\n",
    "    average_accuracies.append(accuracy_mean)\n",
    "\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy:\n",
      "Logistic Regression: 0.8687179487179486\n",
      "Decision Tree: 0.7641025641025639\n",
      "Random Forest: 0.8241025641025641\n",
      "K-Nearest Neighbors: 0.6053846153846154\n",
      "Gradient Boosting: 0.7899999999999999\n",
      "Multinomial Naive Bayes: 0.8387179487179487\n",
      "\n",
      "Data distribution:\n",
      "- Train: 520  \n",
      "- Test: 130\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan rata-rata akurasi\n",
    "print(\"Average accuracy:\")\n",
    "for model_name, accuracy in zip(models.keys(), average_accuracies):\n",
    "    print(f\"{model_name}: {accuracy}\")\n",
    "    \n",
    "print(\"\\nData distribution:\\n- Train: {}  \\n- Test: {}\".format(len(y_train),len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'Logistic Regression' telah disimpan dalam file Logistic Regression.pkl\n",
      "Model 'Decision Tree' telah disimpan dalam file Decision Tree.pkl\n",
      "Model 'Random Forest' telah disimpan dalam file Random Forest.pkl\n",
      "Model 'K-Nearest Neighbors' telah disimpan dalam file K-Nearest Neighbors.pkl\n",
      "Model 'Gradient Boosting' telah disimpan dalam file Gradient Boosting.pkl\n",
      "Model 'Multinomial Naive Bayes' telah disimpan dalam file Multinomial Naive Bayes.pkl\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "for model_name, model in models.items():\n",
    "    # Menyimpan model ke file\n",
    "    filename = f'{model_name}.pkl'\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    \n",
    "    print(f\"Model '{model_name}' telah disimpan dalam file {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model to compare the results\n",
    "# Muat model Logistic Regression\n",
    "with open('Logistic Regression.pkl', 'rb') as f:\n",
    "    logreg_model = pickle.load(f)\n",
    "\n",
    "# Muat model Decision Tree\n",
    "with open('Decision Tree.pkl', 'rb') as f:\n",
    "    dt_model = pickle.load(f)\n",
    "\n",
    "# Muat model Random Forest\n",
    "with open('Random Forest.pkl', 'rb') as f:\n",
    "    rf_model = pickle.load(f)\n",
    "\n",
    "# Muat model K-Nearest Neighbors\n",
    "with open('K-Nearest Neighbors.pkl', 'rb') as f:\n",
    "    knn_model = pickle.load(f)\n",
    "\n",
    "# Muat model Gradient Boosting\n",
    "with open('Gradient Boosting.pkl', 'rb') as f:\n",
    "    gb_model = pickle.load(f)\n",
    "\n",
    "# Muat model Naive Bayes\n",
    "with open('Multinomial Naive Bayes.pkl', 'rb') as f:\n",
    "    nb_model = pickle.load(f)\n",
    "\n",
    "# Muat model Naive Bayes\n",
    "with open('true_labels.pkl', 'rb') as f:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "-----------------------------------\n",
      "Akurasi: 0.9538461538461539\n",
      "Presisi: 0.9705882352941176\n",
      "Recall: 0.9428571428571428\n",
      "F1-Score: 0.9565217391304348\n",
      " \n",
      "DecisionTreeClassifier()\n",
      "-----------------------------------\n",
      "Akurasi: 0.9307692307692308\n",
      "Presisi: 0.9420289855072463\n",
      "Recall: 0.9285714285714286\n",
      "F1-Score: 0.935251798561151\n",
      " \n",
      "RandomForestClassifier()\n",
      "-----------------------------------\n",
      "Akurasi: 0.9769230769230769\n",
      "Presisi: 0.9855072463768116\n",
      "Recall: 0.9714285714285714\n",
      "F1-Score: 0.9784172661870504\n",
      " \n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=3)\n",
      "-----------------------------------\n",
      "Akurasi: 0.7153846153846154\n",
      "Presisi: 0.6542056074766355\n",
      "Recall: 1.0\n",
      "F1-Score: 0.7909604519774012\n",
      " \n",
      "GradientBoostingClassifier()\n",
      "-----------------------------------\n",
      "Akurasi: 0.9230769230769231\n",
      "Presisi: 0.9838709677419355\n",
      "Recall: 0.8714285714285714\n",
      "F1-Score: 0.9242424242424242\n",
      " \n",
      "MultinomialNB()\n",
      "-----------------------------------\n",
      "Akurasi: 0.8384615384615385\n",
      "Presisi: 0.855072463768116\n",
      "Recall: 0.8428571428571429\n",
      "F1-Score: 0.8489208633093526\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Gunakan model yang telah dimuat kembali dengan looping\n",
    "models_to_use = [logreg_model, dt_model, rf_model, knn_model, gb_model, nb_model]\n",
    "for i, model in enumerate(models_to_use):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label='Bullying')\n",
    "    recall = recall_score(y_test, y_pred, pos_label='Bullying')\n",
    "    f1_ = f1_score(y_test, y_pred, pos_label='Bullying')\n",
    "\n",
    "    # Menampilkan hasil evaluasi model\n",
    "    print(model)\n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"Akurasi:\", accuracy)\n",
    "    print(\"Presisi:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-Score:\", f1_)\n",
    "    print(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
